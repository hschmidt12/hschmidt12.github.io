[
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Resources",
    "section": "",
    "text": "I am a member of the Applicant Team for the Application Statement Feedback Program, a volunteer-driven initiative to level the playing field in Psychology PhD program admissions. I’m also a co-director of the Temple University Coding Outreach Group, a student-led organization aiming to make computer programming approachable and achievable. You can find out more information about these two organizations, as well as links to sign up for annual programming, below!"
  },
  {
    "objectID": "resources.html#application-statement-feedback-program",
    "href": "resources.html#application-statement-feedback-program",
    "title": "Resources",
    "section": "Application Statement Feedback Program",
    "text": "Application Statement Feedback Program\n\n\n\n\n\n\nThe Application Statement Feedback Program is a volunteer-driven program to help psychology PhD applicants write a statement that makes the strongest case for their admission, with a focus on underrepresented minority applicants and those who do not have access to mentors or resources that are “in the know” about the PhD application process. By providing support to applicants, our goal is to make the psychology PhD application process more transparent and equitable for all aspiring psychological researchers. Applicants can find more information about participating in the program here. Those interested in volunteering as a statement editor can learn more about getting involved here."
  },
  {
    "objectID": "resources.html#coding-outreach-group",
    "href": "resources.html#coding-outreach-group",
    "title": "Resources",
    "section": "Coding Outreach Group",
    "text": "Coding Outreach Group\n\n\n\n\n\n\nThe Coding Outreach Group at Temple hosts annual coding bootcamps for beginners, hands-on workshops for intermediate to advanced coders, and regular office hours for people of all coding levels to find solutions to coding problems. Our educational materials are free and publicly available so individuals within and outside of the Temple community can learn at their own pace. Click here for more information about our most recent (2023) summer workshop series. A full repository of all materials and tutorials can be found on our GitHub."
  },
  {
    "objectID": "resources.html#additional-resources-for-applying-to-phd-programs-in-psychology",
    "href": "resources.html#additional-resources-for-applying-to-phd-programs-in-psychology",
    "title": "Resources",
    "section": "Additional resources for applying to PhD programs in psychology",
    "text": "Additional resources for applying to PhD programs in psychology\n\n“How applying to graduate school works” - the Sokol-Hessner Lab, University of Denver\nHarvard Psychology’s PhD Resources and Online Tips\n“Mitch’s Uncensored Advice for Applying to Graduate School in Clinical Psychology” - Mitch Prinstein, University of North Carolina (useful for both clinical and non-clinical programs)\nTemple University’s Doctoral Program in Psychology & Neuroscience"
  },
  {
    "objectID": "resources.html#professional-development",
    "href": "resources.html#professional-development",
    "title": "Resources",
    "section": "Professional development",
    "text": "Professional development\n\nCreating a simple and effective academic personal website\nAmerican Psychological Association - Tips for Determining Authorship Credit"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Helen Schmidt",
    "section": "",
    "text": "I’m a psychology Ph.D. student in the Social and Affective Neuroscience Lab at Temple University, specializing in social neuroscience and quantitative methods. Under the guidance of Dr. Chelsea Helion, I study social and affective cognition by employing a multimodal analytic approach that combines behavioral and neuroimaging tools with machine learning and computational methods. My research is supported by an NIH F31 Fellowship from the National Heart, Lung, and Blood Institute (NHLBI).\nI have a bachelor of science in biology from Tufts University and a master of science in clinical neuroscience from University College London.\nOutside of the lab, I can be found reading books, traveling, drinking coffee, and spending time outside. I’m also a big data viz enthusiast - you can find some of my recent projects in my portfolio."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Helen Schmidt",
    "section": "",
    "text": "Hi, I’m Helen!\nI’m a psychology Ph.D. candidate in the Social and Affective Neuroscience Lab at Temple University, specializing in quantitative methods. I study social and affective cognition by employing a multimodal analytic approach that combines behavioral and neuroimaging with machine learning and computational modeling. My research is supported by an NIH F31 Fellowship from the National Heart, Lung, and Blood Institute (NHLBI)\nI have a bachelor of science in biology from Tufts University and a master of science in clinical neuroscience from University College London.\nOutside of the lab, I can be found reading books, traveling, drinking coffee, and spending time outside. I’m also a big data viz enthusiast - you can find some of my recent projects in my portfolio."
  },
  {
    "objectID": "posts/2023-04-01-Map-Challenge/index.html",
    "href": "posts/2023-04-01-Map-Challenge/index.html",
    "title": "30 Day Map Challenge",
    "section": "",
    "text": "Every November, the #30DayMapChallenge encourages data visualization enthusiasts to create original maps using publicly-available geospatial data. Every day presented a new theme, and I used R to create my maps around these themes. This was a fun experience, and I was really proud of how much I learned about working with geospatial data in R by the end of the month. All corresponding code and individual maps can be found on my GitHub."
  },
  {
    "objectID": "posts/2023-05-01-Chart-Challenge/index.html",
    "href": "posts/2023-05-01-Chart-Challenge/index.html",
    "title": "30 Day Chart Challenge",
    "section": "",
    "text": "In April 2023, I took part in the #30DayChartChallenge, a community-driven event with the goal of creating unique and creative data visualizations. Every day presented a new topic, and I used R to create my charts around these topics. While I didn’t complete as many days of the challenge as I would have liked, I’m happy to have had the excuse to try some new ggplot2 visualizations. All corresponding code and individual charts can be found on my GitHub."
  },
  {
    "objectID": "posts/2023-08-04-Generative-Art/index.html",
    "href": "posts/2023-08-04-Generative-Art/index.html",
    "title": "Generating Art in R",
    "section": "",
    "text": "Today I want to combine two of hobbies of mine: programming and art. This demo will use two packages available for R, generativeart and aRtsy. Using these packages, I can create unique images using formulas and random parameters. Let’s see what happens!\nMore information about the generativeart package can be found here, and more information about the aRtsy package can be found here.\n# load packages\n# use install.packages(\"PACKAGE NAME\") if these aren't already installed locally\nlibrary(tidyverse)\nlibrary(aRtsy)\nlibrary(generativeart)"
  },
  {
    "objectID": "posts/2023-08-04-Generative-Art/index.html#generativeart",
    "href": "posts/2023-08-04-Generative-Art/index.html#generativeart",
    "title": "Generating Art in R",
    "section": "generativeart",
    "text": "generativeart\nLet’s start off with the generativeart package. I need to define an image path to save my generated images. I can also set up a logfile spreadsheet to keep track of the images I generate, their formulas, and the random seeds that determine the random numbers in the formula.\n\n# set up image path\nIMG_PATH &lt;- \"./images/\"\n# set up logfiles\nLOGFILE_PATH &lt;- \"./logfile.csv\"\n\n\n# include a specific formula\nmy_formula &lt;- list(\n  x = quote(runif(1, -1, 1) * x_i^2 - sin(y_i^5)),\n  y = quote(runif(1, -1, 1) * y_i^3 - cos(x_i^2))\n)\n\n# call the main function to create an image with a polar coordinate system\ngenerate_img(formula = my_formula, nr_of_img = 1, polar = TRUE, \n             filetype = \"png\", color = \"white\", background_color = \"black\")\n\nAfter trying a variety of formulas, here are some of my favorites created:"
  },
  {
    "objectID": "posts/2023-08-04-Generative-Art/index.html#artsy",
    "href": "posts/2023-08-04-Generative-Art/index.html#artsy",
    "title": "Generating Art in R",
    "section": "aRtsy",
    "text": "aRtsy\nNow that we’ve explored generativeart, let’s dive into aRtsy. This package includes an impressive number of functions with the goal of making generative art accessible, standardized, and fun. Because render times in R can be quite long, I’ll save each of these artworks using the saveCanvas() function and display the rendered image below each code chunk. For each artwork, I played around with the seed number until I got a result/pattern I liked.\n\n# define some palettes to use (thanks coolers.co!)\npalette1 &lt;- c(\"#1b998b\",\"#2d3047\",\"#fffd82\",\"#ff9b71\",\"#e84855\")\npalette2 &lt;- c(\"#4357ad\",\"#48a9a6\",\"#e4dfda\",\"#d4b483\",\"#c1666b\")\npalette3 &lt;- c(\"#fff8f0\",\"#9e2b25\",\"#51355a\",\"#2a0c43\",\"#f5f8de\")\npalette4 &lt;- c(\"#c5fffd\",\"#88d9e6\",\"#8b8bae\",\"#526760\",\"#374b4a\")\npalette5 &lt;- c(\"#000000\",\"#14213d\",\"#fca311\",\"#e5e5e5\",\"#ffffff\")\n\n\n\n\n# decorative tiles\nset.seed(100)\nartwork &lt;- canvas_tiles(colors = palette2,\n                        background = \"white\",\n                        size = 3,\n                        col.line = \"black\")\nsaveCanvas(artwork, \n           filename = \"./images/tiles.png\")\n\n\n\n\n\n\n\n\n\n# watercolor\nset.seed(200)\nartwork &lt;- canvas_watercolors(colors = palette1,\n                              background = \"white\",\n                              layers = 50,\n                              depth = 2,\n                              resolution = 200)\nsaveCanvas(artwork, \n           filename = \"./images/watercolor.png\")\n\n\n\n\n\n\n\n\n\n# blacklights\nset.seed(5)\nartwork &lt;- canvas_blacklight(colors = palette3,\n                             n = 500)\nsaveCanvas(artwork, \n           filename = \"./images/blacklight.png\")\n\n\n\n\n\n\n\n\n\n# fractal\nset.seed(200)\nartwork &lt;- canvas_mandelbrot(colors = palette5,\n                             iterations = 200,\n                             zoom = 2,\n                             set = \"julia\")\nsaveCanvas(artwork, \n           filename = \"./images/fractal.png\")\n\n\n\n\n\n\n\n\n\n# Recamán's sequence\nset.seed(50)\nartwork &lt;- canvas_recaman(colors = palette5,\n                          background = \"grey\",\n                          iterations = 300,\n                          start = 15,\n                          angle = 0,\n                          size = 0.25,\n                          closed = TRUE,\n                          curvature = 10)\nsaveCanvas(artwork, \n           filename = \"./images/recaman.png\")\n\n\n\n\n\n\n\n\n\n# mesh\nset.seed(10)\nartwork &lt;- canvas_mesh(colors = c(\"black\",\"lightgrey\"),\n                       background = \"#450159\",\n                       transform = \"svm\")\nsaveCanvas(artwork, \n           filename = \"./images/mesh.png\")\n\n\n\n\n\n\n\n\n\n# flow fields\nset.seed(10)\nartwork &lt;- canvas_flow(colors = palette4,\n                       background = \"lightgrey\",\n                       lwd = 0.5,\n                       lines = 1500,\n                       iterations = 200,\n                       outline = \"circle\")\nsaveCanvas(artwork, \n           filename = \"./images/flow.png\")"
  },
  {
    "objectID": "posts/2023-12-01-Map-Challenge/index.html",
    "href": "posts/2023-12-01-Map-Challenge/index.html",
    "title": "30 Day Map Challenge",
    "section": "",
    "text": "Every November, the #30DayMapChallenge brings together data viz enthusaists in an online challenge to create original maps using geospatial data. I first took part in 2022, and I was thrilled to make a new set of maps in 2023. All corresponding code and maps can be found on my GitHub."
  },
  {
    "objectID": "posts/2024-08-01-Geospatial-Tutorial/index.html",
    "href": "posts/2024-08-01-Geospatial-Tutorial/index.html",
    "title": "Geospatial Analysis & Cartography in R",
    "section": "",
    "text": "Cartography is the process of creating maps. It can be thought of as a subset of geography, with the goal of communicating geographic information effectively (and creatively!).\nEarly maps were often hand-drawn or painted, and they used information gathered from explorer observations and surveying techniques. These early maps often weren’t very accurate, but inventions like the compass, telescope, and ultimately satellite imagery greatly increased the accuracy of modern maps.\nAt their core, maps strike a balance between capturing objective geographic information and subjective creative design. This combination makes maps both powerful sources of information and potential sources of bias. A classic example of pronounced bias is in the widespread use of the Mercator projection, which maximizes the size of land closer to the north and south poles (e.g., Europe) and minimizes land closer to the equator (e.g., Africa). This projection has been criticized for its subjective representation of regions at higher latitudes as having more power and importance, where European imperial powers were concentrated during the years of early Western mapmaking.\nWith this in mind, there are a lot of decisions one must make as a mapmaker. In order to represent geographic information effectively and tell a data-driven story, there are certain key map elements to consider.\n\n\n\nAccording to the International Cartographic Association, some of the important things to consider when creating a map are as follows:\n\n\nThe scale of a map reflects the ratio of map size to geographic size. This information is often presented as a guide denoting how many inches or centimeters on a map correspond to the number of feet, meters, or miles on the ground. Map scale also represents a compromise between the amount of detail and the expanse of geographic information you want to show.\n\n\n\nIn most Western maps, geographic locations will be reflected using latitude and longitude. You can think of the intersecting planes of latitude and longitude like an intersection of X and Y axes. Latitude reflects the geographic point moving east and west around the Earth, while longitude reflects the geographic point moving north and south around the Earth.\n\n\n\nBecause the Earth is round, and most printed maps are flat, we need to choose a suitable projection to represent the curved features of the Earth on a flat plane. As mentioned earlier, the most common is the Mercator projection, but there are a lot of options for smaller-scale maps. Some countries use specific projections and coordinate reference systems compared to others, and we can specify these reference systems and projections in digital cartography.\n\n\n\nSymbols are used in maps to describe certain elements depicted, while text is more often used to provide a detailed description of map contents. Depending on the information you’re trying to convey, certain shapes and symbols may be useful icons to reflect the location of public services, locations, or more abstract geospatial information.\n\n\n\nArguably some of the most important features of maps are colors and typography. Color can be used to emphasize certain features and distinguish administrative boundaries, environmental features, and symbols. Selecting colors that are well-suited to the map content can easily turn a simple map into a powerful map (e.g., selecting a red color palette when creating a map of volcano eruptions). Moreover, text makes it easier for viewers to understand the map, and the size, typeface, and color can be manipulated to convey more information.\n\n\n\n\nHow do we actually create these data-driven digital maps? We can use a type of data called geospatial data, which can be thought of location-based data containing information about objects and events that are related to physical locations on Earth’s surface. These datasets often contain locations (usually as coordinates), attributes or characteristics, and time points as they relate to a given object or event.\nGeospatial data is highly informative and complex, but we can leverage specialized packages in R to neatly extract the information and create professional-looking maps all using the language of the tidyverse."
  },
  {
    "objectID": "posts/2024-08-01-Geospatial-Tutorial/index.html#what-is-cartography",
    "href": "posts/2024-08-01-Geospatial-Tutorial/index.html#what-is-cartography",
    "title": "Geospatial Analysis & Cartography in R",
    "section": "",
    "text": "Cartography is the process of creating maps. It can be thought of as a subset of geography, with the goal of communicating geographic information effectively (and creatively!).\nEarly maps were often hand-drawn or painted, and they used information gathered from explorer observations and surveying techniques. These early maps often weren’t very accurate, but inventions like the compass, telescope, and ultimately satellite imagery greatly increased the accuracy of modern maps.\nAt their core, maps strike a balance between capturing objective geographic information and subjective creative design. This combination makes maps both powerful sources of information and potential sources of bias. A classic example of pronounced bias is in the widespread use of the Mercator projection, which maximizes the size of land closer to the north and south poles (e.g., Europe) and minimizes land closer to the equator (e.g., Africa). This projection has been criticized for its subjective representation of regions at higher latitudes as having more power and importance, where European imperial powers were concentrated during the years of early Western mapmaking.\nWith this in mind, there are a lot of decisions one must make as a mapmaker. In order to represent geographic information effectively and tell a data-driven story, there are certain key map elements to consider."
  },
  {
    "objectID": "posts/2024-08-01-Geospatial-Tutorial/index.html#what-is-a-map",
    "href": "posts/2024-08-01-Geospatial-Tutorial/index.html#what-is-a-map",
    "title": "Geospatial Analysis & Cartography in R",
    "section": "",
    "text": "According to the International Cartographic Association, some of the important things to consider when creating a map are as follows:\n\n\nThe scale of a map reflects the ratio of map size to geographic size. This information is often presented as a guide denoting how many inches or centimeters on a map correspond to the number of feet, meters, or miles on the ground. Map scale also represents a compromise between the amount of detail and the expanse of geographic information you want to show.\n\n\n\nIn most Western maps, geographic locations will be reflected using latitude and longitude. You can think of the intersecting planes of latitude and longitude like an intersection of X and Y axes. Latitude reflects the geographic point moving east and west around the Earth, while longitude reflects the geographic point moving north and south around the Earth.\n\n\n\nBecause the Earth is round, and most printed maps are flat, we need to choose a suitable projection to represent the curved features of the Earth on a flat plane. As mentioned earlier, the most common is the Mercator projection, but there are a lot of options for smaller-scale maps. Some countries use specific projections and coordinate reference systems compared to others, and we can specify these reference systems and projections in digital cartography.\n\n\n\nSymbols are used in maps to describe certain elements depicted, while text is more often used to provide a detailed description of map contents. Depending on the information you’re trying to convey, certain shapes and symbols may be useful icons to reflect the location of public services, locations, or more abstract geospatial information.\n\n\n\nArguably some of the most important features of maps are colors and typography. Color can be used to emphasize certain features and distinguish administrative boundaries, environmental features, and symbols. Selecting colors that are well-suited to the map content can easily turn a simple map into a powerful map (e.g., selecting a red color palette when creating a map of volcano eruptions). Moreover, text makes it easier for viewers to understand the map, and the size, typeface, and color can be manipulated to convey more information."
  },
  {
    "objectID": "posts/2024-08-01-Geospatial-Tutorial/index.html#what-is-geospatial-data",
    "href": "posts/2024-08-01-Geospatial-Tutorial/index.html#what-is-geospatial-data",
    "title": "Geospatial Analysis & Cartography in R",
    "section": "",
    "text": "How do we actually create these data-driven digital maps? We can use a type of data called geospatial data, which can be thought of location-based data containing information about objects and events that are related to physical locations on Earth’s surface. These datasets often contain locations (usually as coordinates), attributes or characteristics, and time points as they relate to a given object or event.\nGeospatial data is highly informative and complex, but we can leverage specialized packages in R to neatly extract the information and create professional-looking maps all using the language of the tidyverse."
  },
  {
    "objectID": "posts/2024-08-01-Geospatial-Tutorial/index.html#now-its-your-turn",
    "href": "posts/2024-08-01-Geospatial-Tutorial/index.html#now-its-your-turn",
    "title": "Geospatial Analysis & Cartography in R",
    "section": "Now it’s your turn!",
    "text": "Now it’s your turn!\n\n\nReveal Answer\n# get roads\ninterlaken_roads &lt;- opq(\"Interlaken, Switzerland\") |&gt;\n  add_osm_feature(key = \"highway\") |&gt;\n  osmdata_sf()\n# get water\ninterlaken_water &lt;- opq(\"Interlaken, Switzerland\") |&gt;\n  add_osm_feature(key = \"water\") |&gt;\n  osmdata_sf()\n\n# define circle to cut out a view of interlaken\n# get interlaken city center coordinates (googled \"interlaken coordinates\")\ninterlaken_center &lt;- c(lat = 46.6863,\n                   long = 7.8632)\n# reproject to make circle around center coordinates\ninterlaken_circle &lt;- tibble(lat = interlaken_center[\"lat\"],\n                            long = interlaken_center[\"long\"]) |&gt;\n  st_as_sf(coords = c(\"long\", \"lat\"),\n           crs = 4326) |&gt;\n  st_transform(crs = 2056) |&gt;\n  st_buffer(dist = 2000) |&gt;\n  st_transform(crs = 4326)\n\n# get the intersection between roads/water and circle\n# will take a minute to execute\ninterlaken_roads_cropped &lt;- st_intersection(interlaken_circle,\n                                            interlaken_roads$osm_lines)\ninterlaken_water_cropped &lt;- st_intersection(interlaken_circle,\n                                            interlaken_water$osm_multipolygons$geometry)\n\n# basic\nggplot() +\n  geom_sf(data = interlaken_circle, fill = \"white\") +\n  geom_sf(data = interlaken_roads_cropped, linewidth = 0.05, color = \"black\") +\n  geom_sf(data = interlaken_water_cropped, fill = \"blue\") +\n  coord_sf() +\n  theme_void()"
  },
  {
    "objectID": "posts/2024-08-01-Geospatial-Tutorial/index.html#now-its-your-turn-1",
    "href": "posts/2024-08-01-Geospatial-Tutorial/index.html#now-its-your-turn-1",
    "title": "Geospatial Analysis & Cartography in R",
    "section": "Now it’s your turn!",
    "text": "Now it’s your turn!\nTry using the avalanche coordinates to plot the exact locations for the 2022/23 hydrological year. Use the canton map we already created and geom_sf() to plot the avalanche locations. If you want a bonus challenge, you can color the points by the number of people who died in the avalanches.\nHINT: You’ll need the following code to transform the latitude and longitude variables in the avalanche dataset to sf geometry.\n\nnew_avalanche_sf &lt;- sf::st_as_sf(subset_avalanche_data,\n                                 coords = c(LONGITUDE, LATITUDE),\n                                 crs = 4326)\n\n\n\nReveal Answer\n# subset avalanche dataset to just the 2022/23 hydrological year\navalanche_22_23 &lt;- subset(avalanche, hydrological.year == \"2022/23\")\n# select only variables of interest (just keeps the data cleaner)\navalanche_22_23 &lt;- avalanche_22_23 |&gt;\n  select(start.zone.coordinates.latitude, start.zone.coordinates.longitude,\n         number.dead, shapeName, avalanche.id)\n# rename variables for ease\nnames(avalanche_22_23) &lt;- c(\"lat\", \"long\", \"num_dead\", \"shapeName\", \"ID\")\n# convert to sf object\navalanche_sf &lt;- sf::st_as_sf(avalanche_22_23,\n                     coords = c(2:1),\n                     crs = 4326)\n# plot\nggplot() +\n  geom_sf(data = canton, fill = \"#08171e\", color = \"white\") +\n  geom_sf(data = avalanche_sf, aes(color = num_dead), size = 2) +\n  coord_sf() +\n  theme_void() +\n  scale_color_gradient(low = \"#D3D0CB\", high = \"#D5573B\", name = NULL) +\n  theme(legend.position = \"right\",\n        legend.key.width = unit(0.25, \"cm\"),\n        legend.key.height = unit(1, \"cm\"),\n        plot.background = element_rect(fill = \"white\", color = NA),\n        legend.text = element_text(color = \"#08171e\"))"
  },
  {
    "objectID": "posts/2024-08-01-Geospatial-Tutorial/index.html#openstreetmap-1",
    "href": "posts/2024-08-01-Geospatial-Tutorial/index.html#openstreetmap-1",
    "title": "Geospatial Analysis & Cartography in R",
    "section": "OpenStreetMap",
    "text": "OpenStreetMap\n\n# zurich\nplot &lt;- ggplot() +\n  geom_sf(data = zurich_circle, fill = \"#08171e\") +\n  geom_sf(data = zurich_roads_cropped, linewidth = 0.05, color = \"#D3D0CB\") +\n  geom_sf(data = zurich_water_cropped, fill = \"#247B7B\", color = \"#247B7B\") +\n  coord_sf() +\n  theme_void()\n\nggsave(plot,\n       filename = \"./output/zurich.png\",\n       width = 5,\n       height = 3,\n       units = \"in\",\n       dpi = 600,\n       device = \"png\")\n\n\n\n# interlaken\nplot &lt;- ggplot() +\n  geom_sf(data = interlaken_circle, fill = \"#D3D0CB\") +\n  geom_sf(data = interlaken_roads_cropped, linewidth = 0.05, color = \"#08171e\") +\n  geom_sf(data = interlaken_water_cropped, fill = \"#247B7B\", color = \"#247B7B\") +\n  coord_sf() +\n  theme_void() \n\nggsave(plot,\n       filename = \"./output/interlaken.png\",\n       width = 5,\n       height = 3,\n       units = \"in\",\n       dpi = 600,\n       device = \"png\")"
  },
  {
    "objectID": "posts/2024-08-01-Geospatial-Tutorial/index.html#online-open-data-1",
    "href": "posts/2024-08-01-Geospatial-Tutorial/index.html#online-open-data-1",
    "title": "Geospatial Analysis & Cartography in R",
    "section": "Online Open Data",
    "text": "Online Open Data\n\n# avalanches\nplot &lt;- ggplot() +\n  geom_sf(data = canton, fill = \"white\", color = \"#08171e\") +\n  geom_sf(data = avalanche_summary$geometry, aes(fill = avalanche_summary$canton_prop)) +\n  scale_fill_gradient(low = \"#D3D0CB\", high = \"#D5573B\", name = NULL, labels = scales::label_percent()) +\n  coord_sf() +\n  theme_void() +\n  theme(legend.position = \"right\",\n        legend.key.width = unit(0.25, \"cm\"),\n        legend.key.height = unit(1, \"cm\"),\n        plot.background = element_rect(fill = \"#08171e\", color = NA),\n        legend.text = element_text(color = \"white\"))\n\n# save\nggsave(plot,\n       filename = \"./output/avalanche.png\",\n       width = 5,\n       height = 3,\n       units = \"in\",\n       dpi = 600,\n       device = \"png\")"
  },
  {
    "objectID": "posts/2024-08-01-Geospatial-Tutorial/index.html#elevation-1",
    "href": "posts/2024-08-01-Geospatial-Tutorial/index.html#elevation-1",
    "title": "Geospatial Analysis & Cartography in R",
    "section": "Elevation",
    "text": "Elevation\n\n# get font\nshowtext_auto()\nfont_add_google(name = \"Sacramento\", family = \"sacramento\")\n# elevation\nplot &lt;- ggplot() +\n  geom_sf(data = swiss, fill = \"#08171e\", color = \"#08171e\") +\n  geom_contour(data = alps, aes(x = lat, y = long, z = elevation, color = after_stat(level)), \n               linewidth = 0.3) +\n  scale_color_gradientn(colors = c(\"#042b44\",\"#a1ccdc\"), breaks = c(0,500,4000)) +\n  annotate(geom = \"text\",\n           label = \"Switzerland\",\n           x = -Inf, y = -Inf, hjust = -0.05, vjust = -9.3,\n           size = 60, family = \"sacramento\", color = \"#042b44\") +\n  theme_void() +\n  coord_sf() +\n  theme(legend.position = \"none\",\n        plot.background = element_rect(fill = \"#a1ccdc\", color = NA))\n\n# save\nggsave(plot,\n       filename = \"./output/swiss-elevation.png\",\n       width = 5,\n       height = 3,\n       units = \"in\",\n       dpi = 600,\n       device = \"png\")"
  },
  {
    "objectID": "posts/2023-06-15-Machine-Learning/index.html",
    "href": "posts/2023-06-15-Machine-Learning/index.html",
    "title": "Introduction to Machine Learning in R",
    "section": "",
    "text": "# define packages we need\nlibrary(tidyverse)\nlibrary(palmerpenguins)\nlibrary(stats)\nlibrary(factoextra)\nlibrary(cluster)\nlibrary(formatR)\nlibrary(class)\nlibrary(modelsummary)\nlibrary(kableExtra)\nlibrary(vembedr)\nlibrary(gridExtra)\nlibrary(corrr)\nlibrary(ggcorrplot)\nlibrary(FactoMineR)\nlibrary(rpart)\nlibrary(rpart.plot)\n\nMachine learning (ML) broadly describes the process of teaching computers to learn information. It is widely used in computer science, neuroscience, and data science to train “machines” (e.g., algorithms, models) to learn about information and make predictions or classifications based on that learning. Machine learning is a subset of artificial intelligence (AI), and it has grown in popularity during the recent AI boom. While AI describes the general development of computers that can mimic cognitive function, machine learning is more specific, using algorithms and large amounts of data to make informed decisions for specific tasks.\nMachine learning has become especially popular for researchers in psychology and neuroscience. Thanks to huge increases in computing power and access to datasets with thousands or millions of observations, psychologists have seen great success in applying ML methods to gather insights about human behavior and cognition. ML models can reduce time, effort, and error costs and can be applied flexibly across projects and datasets, including behavioral, survey, and neuroimaging data.\nThe goal of this tutorial is to introduce a variety of machine learning methods that can be applied to psychological data. We will examine the differences between unsupervised and supervised models and in which contexts they are best applied. This tutorial will also touch on model evaluation and comparison, and unpack how to determine certain parameters given your data. This is by no means an exhaustive list of all approaches - these are meant to serve as introductory examples and methods that can be employed specifically in the R programming language. A majority of more complex ML approaches are supported in Python using libraries like PyTorch, TensorFlow, and Keras, and these are more typically what you might see in other ML tutorials.\nThis tutorial is intended to be an introduction to machine learning with R, but you should have some familiarity with scripting and R before starting this tutorial. This tutorial will also discuss reasons for using machine learning alongside more “traditional” data analysis and visualization techniques, and leave room for future directions on applying machine learning tools to relevant psychological and neural datasets.\n\n\n\n\n\n\n\n\n\nWe will use one publicly available dataset throughout the tutorial, accessible through the palmerpenguins R package. This is similar to the native iris dataset in R but serves as a fresh and similarly simple dataset.\nNote: Artwork by @allison_horst. All images included in this tutorial are available for open use under the Creative Commons Attribution 4.0 International License.\n\n\n\n\n# set colors\ncolors &lt;- c(\"#ff6800\", \"#d74fd0\", \"#007176\")\n# set custom plot formatting\nplot.format &lt;- list(theme_classic(), scale_color_manual(values = colors), scale_fill_manual(values = colors))"
  },
  {
    "objectID": "posts/2023-06-15-Machine-Learning/index.html#explore-data",
    "href": "posts/2023-06-15-Machine-Learning/index.html#explore-data",
    "title": "Introduction to Machine Learning in R",
    "section": "Explore data",
    "text": "Explore data\nBefore we start with our ML models, let’s take a moment to explore the data we’re working with.\n\n# load data\ndf &lt;- palmerpenguins::penguins\n# examine data\nhead(df)\n\n# A tibble: 6 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n6 Adelie  Torgersen           39.3          20.6               190        3650\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\ndatasummary_skim(df, type = \"categorical\")\n\n\n \n\n  \n    \n    \n    tinytable_e5hyyqm9tixlxr04nzit\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n        \n              \n                 \n                  \n                N\n                %\n              \n        \n        \n        \n                \n                  species\n                  Adelie   \n                  152\n                  44.2\n                \n                \n                         \n                  Chinstrap\n                  68 \n                  19.8\n                \n                \n                         \n                  Gentoo   \n                  124\n                  36.0\n                \n                \n                  island \n                  Biscoe   \n                  168\n                  48.8\n                \n                \n                         \n                  Dream    \n                  124\n                  36.0\n                \n                \n                         \n                  Torgersen\n                  52 \n                  15.1\n                \n                \n                  sex    \n                  female   \n                  165\n                  48.0\n                \n                \n                         \n                  male     \n                  168\n                  48.8\n                \n        \n      \n    \n\n    \n\n  \n\n\n\ndatasummary_skim(df, type = \"numeric\")\n\n\n \n\n  \n    \n    \n    tinytable_sa06jsnr4e9dnkgougfy\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n        \n              \n                 \n                Unique\n                Missing Pct.\n                Mean\n                SD\n                Min\n                Median\n                Max\n                Histogram\n              \n        \n        \n        \n                \n                  bill_length_mm   \n                  165\n                  1\n                  43.9  \n                  5.5  \n                  32.1  \n                  44.5  \n                  59.6  \n                  \n                \n                \n                  bill_depth_mm    \n                  81 \n                  1\n                  17.2  \n                  2.0  \n                  13.1  \n                  17.3  \n                  21.5  \n                  \n                \n                \n                  flipper_length_mm\n                  56 \n                  1\n                  200.9 \n                  14.1 \n                  172.0 \n                  197.0 \n                  231.0 \n                  \n                \n                \n                  body_mass_g      \n                  95 \n                  1\n                  4201.8\n                  802.0\n                  2700.0\n                  4050.0\n                  6300.0\n                  \n                \n                \n                  year             \n                  3  \n                  0\n                  2008.0\n                  0.8  \n                  2007.0\n                  2008.0\n                  2009.0\n                  \n                \n        \n      \n    \n\n    \n\n  \n\n\n\n# remove penguins with missing data\ndf &lt;- na.omit(df)\n# correlation tables\ndatasummary_correlation(df[, c(\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\",\n    \"body_mass_g\")])\n\n\n \n\n  \n    \n    \n    tinytable_lq2mzar83zv2ny01t80o\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n        \n              \n                 \n                bill_length_mm\n                bill_depth_mm\n                flipper_length_mm\n                body_mass_g\n              \n        \n        \n        \n                \n                  bill_length_mm   \n                  1   \n                  .   \n                  .  \n                  .\n                \n                \n                  bill_depth_mm    \n                  -.23\n                  1   \n                  .  \n                  .\n                \n                \n                  flipper_length_mm\n                  .65 \n                  -.58\n                  1  \n                  .\n                \n                \n                  body_mass_g      \n                  .59 \n                  -.47\n                  .87\n                  1\n                \n        \n      \n    \n\n    \n\n  \n\n\n\n\n\n# frequency of body mass\nggplot(data = df, aes(x = body_mass_g, color = species, group = species, fill = species)) +\n    geom_histogram(alpha = 0.7) + labs(x = \"body mass (g)\", y = \"frequency\",\n    title = \"Frequency of Body Masses by Species\") + plot.format\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n# bill length vs. bill depth\nggplot(data = df, aes(x = bill_length_mm, y = bill_depth_mm, color = species,\n    group = species)) + geom_point() + geom_smooth(method = lm, se = F) + labs(x = \"bill length (mm)\",\n    y = \"bill depth (mm)\", title = \"Penguin Bill Length and Bill Depth by Species\") +\n    plot.format\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n# body mass vs. flipper length\nggplot(data = df, aes(x = body_mass_g, y = flipper_length_mm, color = species,\n    group = species)) + geom_point() + geom_smooth(method = lm, se = F) + labs(x = \"body mass (g)\",\n    y = \"flipper length (mm)\", title = \"Penguin Body Mass and Flipper Length by Species\") +\n    plot.format\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n# just for fun radar plot\nlibrary(fmsb)\n# create a function to normalize the predictors\nnor &lt;- function(x) {\n    (x - min(x))/(max(x) - min(x))\n}\n# normalize the predictor columns\npenguin.norm &lt;- as.data.frame(lapply(df[, c(\"body_mass_g\", \"flipper_length_mm\",\n    \"bill_length_mm\", \"bill_depth_mm\")], nor))\npenguin.norm &lt;- cbind(df$species, penguin.norm)\nnames(penguin.norm)[1] &lt;- \"species\"\n# get average data for each penguin species\npenguins &lt;- penguin.norm %&gt;%\n    group_by(species) %&gt;%\n    summarize(`body mass` = mean(body_mass_g), `flipper\\nlength` = mean(flipper_length_mm),\n        `bill length` = mean(bill_length_mm), `bill\\ndepth` = mean(bill_depth_mm))\npenguins$species &lt;- as.character(penguins$species)\nnames &lt;- penguins$species\npenguins &lt;- penguins[, -1]\nrownames(penguins) &lt;- names\npenguins &lt;- rbind(rep(1, 1), rep(0, 1), penguins)\n\nradarchart(penguins, pcol = colors, plwd = 3, plty = 1, cglcol = \"grey\")\n\n\n\n\nNow that we’ve examined the data that we’re working with, let’s outline how we can leverage machine learning to analyze this data.\nA common area of investigation in psychology are individual difference measures. Machine learning can be particularly useful to group data into groups, revealing underlying structures or similarities that may not be apparent to human raters. With the palmer penguin data, we can use the four data points for each penguin (bill length, bill depth, flipper length, and body mass) and their species grouping to develop a model that can be applied to new data (supervised). We can see how well a model can classify penguin data into species groups when we remove the species labels (unsupervised)."
  },
  {
    "objectID": "posts/2023-06-15-Machine-Learning/index.html#k-nearest-neighbors",
    "href": "posts/2023-06-15-Machine-Learning/index.html#k-nearest-neighbors",
    "title": "Introduction to Machine Learning in R",
    "section": "K-Nearest Neighbors",
    "text": "K-Nearest Neighbors\nK-nearest neighbors (k-NN) is a technique used to classify data into specified classes. Let’s start by using the k-NN algorithm to try to classify our penguin species based on two data dimensions, bill length and bill depth.\n\n# set seed so we get the same results every time\nset.seed(123)\n# generate a random number that is 80% of total number of rows in the\n# dataset; this will be our training set\nran &lt;- sample(1:nrow(df), 0.8 * nrow(df))\n# create a function to normalize the predictors\nnor &lt;- function(x) {\n    (x - min(x))/(max(x) - min(x))\n}\n# normalize the predictor columns\ndf.norm &lt;- as.data.frame(lapply(df[, c(\"bill_length_mm\", \"bill_depth_mm\")],\n    nor))\n# check that normalizing worked\nsummary(df.norm)\n\n bill_length_mm   bill_depth_mm   \n Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.2691   1st Qu.:0.2976  \n Median :0.4509   Median :0.5000  \n Mean   :0.4325   Mean   :0.4839  \n 3rd Qu.:0.6000   3rd Qu.:0.6667  \n Max.   :1.0000   Max.   :1.0000  \n\n\n\n# extract training set\ndf.train &lt;- df.norm[ran, ]\n# extract testing set\ndf.test &lt;- df.norm[-ran, ]\n# extract species name to be used as classification argument in knn\ndf.category &lt;- df[ran, 1]\n\n# run knn function; let's start with 3 neighbors and see how accurate that\n# is\npred &lt;- knn(train = df.train, test = df.test, cl = df.category$species, k = 3)\n\n# show proportion correctly classified\naccuracy &lt;- 100 * sum(df.category$species == pred)/nrow(df.category)\nprint(paste0(\"KNN classification accuracy = \", round(accuracy, digits = 2),\n    \"%\", sep = \"\"))\n\n[1] \"KNN classification accuracy = 39.1%\"\n\n# yikes, not great let's try again with different numbers of neighbors\npred &lt;- knn(train = df.train, test = df.test, cl = df.category$species, k = 10)\naccuracy &lt;- 100 * sum(df.category$species == pred)/nrow(df.category)\nprint(paste0(\"KNN classification accuracy = \", round(accuracy, digits = 2),\n    \"%\", sep = \"\"))\n\n[1] \"KNN classification accuracy = 38.35%\""
  },
  {
    "objectID": "posts/2023-06-15-Machine-Learning/index.html#classification-decision-trees",
    "href": "posts/2023-06-15-Machine-Learning/index.html#classification-decision-trees",
    "title": "Introduction to Machine Learning in R",
    "section": "Classification / Decision Trees",
    "text": "Classification / Decision Trees\nClassification trees (or decision trees) are another supervised learning technique to draw conclusions about a set of data observations. Classification trees are tree models where the target variable (in our case, the species variable) can take on a set of discrete values (e.g., Chinstrap, Gentoo, Adelie). We can train a decision tree model on a selection of our data and then apply it to a set of test data, and see how accurately the decision tree can categorize penguins with their correct species label.\n\nset.seed(123)\n# shuffle rows to ensure we take a random sample for training and testing\n# sets\nshuffle.index &lt;- sample(1:nrow(df))\nshuffle.df &lt;- df[shuffle.index, ]\n\n# we need to create a testing and training set, 80% trains the model data\n# = dataset to train model, size = percent split, train = T creates train\n# set otherwise test\ncreate_train_set &lt;- function(data, size = 0.8, train = TRUE) {\n    n_row = nrow(data)\n    total_row = size * n_row\n    train_sample &lt;- 1:total_row\n    if (train == TRUE) {\n        return(data[train_sample, ])\n    } else {\n        return(data[-train_sample, ])\n    }\n}\n# make sure to use the new shuffled data frame!\ndf.train &lt;- create_train_set(shuffle.df, 0.8, train = T)\ndf.test &lt;- create_train_set(shuffle.df, 0.8, train = F)\n\n# fit decision tree model\nfit &lt;- rpart(species ~ ., data = df.train, method = \"class\")\nrpart.plot(fit, extra = 106)\n\nWarning: extra=106 but the response has 3 levels (only the 2nd level is\ndisplayed)\n\n\n\n\n# now let's predict on the test dataset\npredicted.test &lt;- predict(fit, df.test, type = \"class\")\ntable_predicted &lt;- table(df.test$species, predicted.test)\ntable_predicted\n\n           predicted.test\n            Adelie Chinstrap Gentoo\n  Adelie        26         2      0\n  Chinstrap      1        14      0\n  Gentoo         0         0     24\n\n# it did pretty well! it correctly predicted 26 Adelie penguins but\n# incorrectly classified 2 Chinstrap penguins as Adelie penguins\n\n# measure performance\naccuracy &lt;- sum(diag(table_predicted))/sum(table_predicted)\naccuracy &lt;- accuracy * 100\nprint(paste0(\"Decision tree classification accuracy = \", round(accuracy, digits = 2),\n    \"%\", sep = \"\"))\n\n[1] \"Decision tree classification accuracy = 95.52%\""
  },
  {
    "objectID": "posts/2023-06-15-Machine-Learning/index.html#k-means-clustering",
    "href": "posts/2023-06-15-Machine-Learning/index.html#k-means-clustering",
    "title": "Introduction to Machine Learning in R",
    "section": "K-means clustering",
    "text": "K-means clustering\nK-means clustering is an unsupervised technique that assigns each observation to one of k clusters based on the nearest cluster centroid. We have to specify the number of clusters we might expect from the data (we can also do this iteratively to find the optimal number of clusters based on the data) - this is our k.\n\nI find this series of visualizations to be really helpful in understanding the process of assigning observations to these clusters.\n\nIn this example, we’re going to try using a k of 3 as a hypothesized number of clusters for species and a k of 2 as a hypothesized number of clusters for penguin sex. For simplicity, we will be using only flipper length and bill length observations. K-means clustering can handle more than 2 dimensions of data, but to best outline how k-means clustering compares to the actual structure of the data, we will just use these two for now.\n\n# subset flipper length and bill length from unlabeled data frame\nul.subset &lt;- df.ul %&gt;%\n    select(bill_length_mm, flipper_length_mm)\n\n# let's visualize the data with species labels from our main data frame\nggplot(data = df, aes(x = bill_length_mm, y = flipper_length_mm, color = species,\n    group = species)) + geom_point() + labs(x = \"bill length (mm)\", y = \"flipper length (mm)\",\n    title = \"Penguin Bill Length and Flipper Length by Species\") + plot.format\n\n\n\n# run k-means clustering for species (k = 3)\nset.seed(123)\nk3 &lt;- stats::kmeans(ul.subset, 3, nstart = 25)\nstr(k3)\n\nList of 9\n $ cluster     : int [1:333] 2 2 3 2 2 2 3 2 2 3 ...\n $ centers     : num [1:3, 1:2] 47.6 38.5 45.9 217 187.1 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : chr [1:3] \"1\" \"2\" \"3\"\n  .. ..$ : chr [1:2] \"bill_length_mm\" \"flipper_length_mm\"\n $ totss       : num 75148\n $ withinss    : num [1:3] 6521 3301 4037\n $ tot.withinss: num 13859\n $ betweenss   : num 61289\n $ size        : int [1:3] 124 115 94\n $ iter        : int 3\n $ ifault      : int 0\n - attr(*, \"class\")= chr \"kmeans\"\n\nk3\n\nK-means clustering with 3 clusters of sizes 124, 115, 94\n\nCluster means:\n  bill_length_mm flipper_length_mm\n1       47.65000          217.0000\n2       38.45304          187.0522\n3       45.94574          196.8404\n\nClustering vector:\n  [1] 2 2 3 2 2 2 3 2 2 3 2 3 3 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 2 2 2 2 3\n [38] 2 3 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 3 2 2 3 3 2 3 2 2 2 3\n [75] 2 3 2 2 2 3 2 2 2 2 3 3 2 2 2 1 2 3 2 3 2 3 2 2 2 2 3 2 2 3 3 3 2 3 2 3 2\n[112] 3 2 2 2 3 2 3 2 3 2 3 2 1 2 3 2 3 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 3 1 1\n[149] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 1\n[186] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[223] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[260] 1 1 1 1 1 1 3 3 3 2 3 3 2 3 3 3 3 3 2 3 3 3 3 3 3 3 2 3 2 3 3 3 3 3 3 3 2\n[297] 3 2 3 3 3 3 1 3 3 1 2 3 3 3 3 3 1 3 3 3 3 3 3 2 3 3 3 3 3 3 3 3 1 3 3 1 3\n\nWithin cluster sum of squares by cluster:\n[1] 6520.630 3301.413 4036.900\n (between_SS / total_SS =  81.6 %)\n\nAvailable components:\n\n[1] \"cluster\"      \"centers\"      \"totss\"        \"withinss\"     \"tot.withinss\"\n[6] \"betweenss\"    \"size\"         \"iter\"         \"ifault\"      \n\nfviz_cluster(k3, data = ul.subset) + theme_classic()\n\n\n\n# let's visualize the data using sex labels\nggplot(data = df, aes(x = bill_length_mm, y = flipper_length_mm, color = sex,\n    group = sex)) + geom_point() + labs(x = \"bill length (mm)\", y = \"flipper length (mm)\",\n    title = \"Penguin Bill Length and Flipper Length by Sex\") + plot.format\n\n\n\n# run k-means clustering for sex (k = 2)\nset.seed(123)\nk2 &lt;- stats::kmeans(ul.subset, 2, nstart = 25)\nstr(k2)\n\nList of 9\n $ cluster     : int [1:333] 2 2 2 2 2 2 2 2 2 2 ...\n $ centers     : num [1:2, 1:2] 47.8 41.5 216.2 190.9\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : chr [1:2] \"1\" \"2\"\n  .. ..$ : chr [1:2] \"bill_length_mm\" \"flipper_length_mm\"\n $ totss       : num 75148\n $ withinss    : num [1:2] 8012 12938\n $ tot.withinss: num 20950\n $ betweenss   : num 54198\n $ size        : int [1:2] 133 200\n $ iter        : int 1\n $ ifault      : int 0\n - attr(*, \"class\")= chr \"kmeans\"\n\nk2\n\nK-means clustering with 2 clusters of sizes 133, 200\n\nCluster means:\n  bill_length_mm flipper_length_mm\n1       47.76241          216.1504\n2       41.48600          190.8700\n\nClustering vector:\n  [1] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n [38] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n [75] 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n[112] 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1\n[149] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[186] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[223] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[260] 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2\n[297] 2 2 1 2 2 2 1 2 1 1 2 2 2 2 2 2 1 2 2 2 2 2 1 2 2 2 1 2 2 1 2 2 1 2 2 1 2\n\nWithin cluster sum of squares by cluster:\n[1]  8011.965 12937.821\n (between_SS / total_SS =  72.1 %)\n\nAvailable components:\n\n[1] \"cluster\"      \"centers\"      \"totss\"        \"withinss\"     \"tot.withinss\"\n[6] \"betweenss\"    \"size\"         \"iter\"         \"ifault\"      \n\nfviz_cluster(k2, data = ul.subset) + theme_classic()\n\n\n\n\nHow do we determine the “optimal” number of clusters based on our data? There are a few different methods we can use to find the optimal k to specify. This process can be somewhat subjective, but we can use three different methods to attempt to reach a consensus. Partitioning the data with k-means clustering aims to minimize the intra-cluster variation.\nThe first method is called the Elbow Method and aims to find a k that has the smallest within-cluster sum of squares (WSS). The total WSS measures how compact the clusters are. The Elbow Method examines total WSS as a function of the number of clusters such that adding another cluster doesn’t improve the total WSS.\n\nset.seed(123)\nfviz_nbclust(ul.subset, kmeans, method = \"wss\")\n\n\n\n\nWe can also use a method called the Average Silhouette Method which measures the quality of a clustering. A high average silhouette width indicates good clustering. With this method, the optimal number for k is the one that maximizes the average silhouette over a range of possible values for k.\n\nset.seed(123)\nfviz_nbclust(ul.subset, kmeans, method = \"silhouette\")\n\n\n\n\nFinally, we can use a statistical method called the Gap Statistic Method which compares data against a null hypothesis. The gap statistic compares the total within intra-cluster variation for different values of k with their expected values under a null reference distribution of the data. The optimal cluster number is a value that maximizes the gap statistic and means that the clustering structure is far from the random uniform distribution of observations.\n\nset.seed(123)\ngap_stat &lt;- clusGap(ul.subset, FUN = kmeans, nstart = 25, K.max = 10, B = 50)\nfviz_gap_stat(gap_stat)\n\n\n\n\nOk so from these three methods, we have a mixture of suggestions. The Elbow Method suggests 4 clusters, the Silhouette Method suggests 2 clusters, and the Gap Statistic Method suggests 4 clusters. There is no clear consensus, but we can be relatively confident that using a k between 2 and 4 is likely optimal. Let’s see how these different k values look with our data!\n\n# calculate kmeans for 2, 3, and 4 centers\nk2 &lt;- kmeans(ul.subset, centers = 2, nstart = 25)\nk3 &lt;- kmeans(ul.subset, centers = 3, nstart = 25)\nk4 &lt;- kmeans(ul.subset, centers = 4, nstart = 25)\n# define plots to compare\np1 &lt;- fviz_cluster(k2, geom = \"point\", data = ul.subset) + ggtitle(\"k = 2\") +\n    theme_classic()\np2 &lt;- fviz_cluster(k3, geom = \"point\", data = ul.subset) + ggtitle(\"k = 3\") +\n    theme_classic()\np3 &lt;- fviz_cluster(k4, geom = \"point\", data = ul.subset) + ggtitle(\"k = 4\") +\n    theme_classic()\n# plot together\ngrid.arrange(p1, p2, p3, nrow = 2)"
  },
  {
    "objectID": "posts/2023-06-15-Machine-Learning/index.html#principal-components-analysis",
    "href": "posts/2023-06-15-Machine-Learning/index.html#principal-components-analysis",
    "title": "Introduction to Machine Learning in R",
    "section": "Principal Components Analysis",
    "text": "Principal Components Analysis\nPrincipal Components Analysis (PCA) is a method to reduce dimensionality in a dataset using unsupervised machine learning models. We have four dimensions for each penguin in our dataset (bill length, bill depth, body mass, and flipper length), but as we discussed in k-means clustering, it’s difficult to visualize all four of these dimensions together. Using PCA, we can transform the data into lower-dimensional space and collapse highly correlated variables together. We can then extract important information and visualize the data more easily.\nThe first step we’ll want to take for PCA is data normalization. We can use the same function we created in the supervised learning section. Then we need to compute a covariance matrix from the normalized data (using the corrr package).\n\n# normalize the unlabeled data frame\ndf.norm &lt;- as.data.frame(lapply(df.ul, nor))\n# compute correlation matrix\ndf.corr &lt;- cor(df.norm)\n# visualize correlation matrix\nggcorrplot(df.corr)\n\n\n\n# conduct PCA\ndf.pca &lt;- princomp(df.corr)\nsummary(df.pca)\n\nImportance of components:\n                         Comp.1     Comp.2      Comp.3 Comp.4\nStandard deviation     1.128537 0.22631151 0.067070224      0\nProportion of Variance 0.958087 0.03852893 0.003384022      0\nCumulative Proportion  0.958087 0.99661598 1.000000000      1\n\n# view loadings of first two components only\ndf.pca$loadings[, 1:2]\n\n                      Comp.1     Comp.2\nbill_length_mm     0.3536264  0.9238103\nbill_depth_mm     -0.5572550  0.1601286\nflipper_length_mm  0.5544175 -0.1353666\nbody_mass_g        0.5069877 -0.3203266\n\n# scree plot\nfviz_eig(df.pca, addlabels = T, barfill = \"deepskyblue3\", barcolor = \"deepskyblue3\")\n\n\n\n# biplot of attributes\nfviz_pca_var(df.pca, col.var = \"deepskyblue3\")"
  },
  {
    "objectID": "posts/2023-03-07-Data-Viz/index.html",
    "href": "posts/2023-03-07-Data-Viz/index.html",
    "title": "Data Visualizations in R",
    "section": "",
    "text": "This demo uses an open-source dataset to explore different data wrangling and plotting techniques in R. Data organization is hugely important because it can impact the quality and accuracy of any statistical tests or visualizations. A popular collection of data organization packages is the tidyverse, which all share an “underlying design philosophy, grammar, and data structure” (see more).\nThe basic structure of tidy data is every variable goes into a column and every column is a variable. Using this framework, we can manipulate the data to calculate new values, run statistical tests, and generate a graphic. In this demo, I will primarily use dplyr, ggplot2, and tidyr to organize my data and make some beautiful plots. I will be using the Top Hits Spotify from 2000 - 2019 dataset, available on Kaggle."
  },
  {
    "objectID": "posts/2023-03-07-Data-Viz/index.html#load-packages-and-data",
    "href": "posts/2023-03-07-Data-Viz/index.html#load-packages-and-data",
    "title": "Data Visualizations in R",
    "section": "Load packages and data",
    "text": "Load packages and data\nFirst, I will load the packages I need. If you do not already have tidyverse packages installed on your computer, you should install them using install.packages('tidyverse') first. The other packages I’m loading will be useful for customizing my plots. I’ll also set a global theme to theme_classic.\n\nlibrary(ggpubr)                 # ggplot customization\nlibrary(Rmisc)                  # basic statistics helper\nlibrary(gganimate)              # animate plots\nlibrary(scales)                 # ggplot scale customization\nlibrary(icons)                  # icon library\nlibrary(tidyverse)              # load all tidyverse packages\ntheme_set(theme_classic())      # set classic theme\ndownload_fontawesome()\n\nI will also read in the dataset as df_raw and look at the first few rows to get a sense of the variables I’m working with.\n\n# read in data\ndf_raw &lt;- read.csv('./data/songs_normalize.csv')\n# see first six rows of all variables\nhead(df_raw)\n\n          artist                   song duration_ms explicit year popularity\n1 Britney Spears Oops!...I Did It Again      211160    False 2000         77\n2      blink-182   All The Small Things      167066    False 1999         79\n3     Faith Hill                Breathe      250546    False 1999         66\n4       Bon Jovi           It's My Life      224493    False 2000         78\n5         *NSYNC            Bye Bye Bye      200560    False 2000         65\n6          Sisqo             Thong Song      253733     True 1999         69\n  danceability energy key loudness mode speechiness acousticness\n1        0.751  0.834   1   -5.444    0      0.0437       0.3000\n2        0.434  0.897   0   -4.918    1      0.0488       0.0103\n3        0.529  0.496   7   -9.007    1      0.0290       0.1730\n4        0.551  0.913   0   -4.063    0      0.0466       0.0263\n5        0.614  0.928   8   -4.806    0      0.0516       0.0408\n6        0.706  0.888   2   -6.959    1      0.0654       0.1190\n  instrumentalness liveness valence   tempo             genre\n1         1.77e-05   0.3550   0.894  95.053               pop\n2         0.00e+00   0.6120   0.684 148.726         rock, pop\n3         0.00e+00   0.2510   0.278 136.859      pop, country\n4         1.35e-05   0.3470   0.544 119.992       rock, metal\n5         1.04e-03   0.0845   0.879 172.656               pop\n6         9.64e-05   0.0700   0.714 121.549 hip hop, pop, R&B\n\n\nBased on the data, it looks like I have 18 variables. These are further explained on the Kaggle page for this dataset. This is a lot of data, so it’s useful to break down and organize the data depending on my analysis questions. This is where dplyr and tidyr come in handy.\nI also noticed that despite the dataset saying it includes songs from 2000 to 2019, I see some songs from before 2000 and after 2019 included. I will remove those observations.\n\ndf &lt;- subset(df_raw, df_raw$year &gt;= 2000 & df_raw$year &lt;= 2019)"
  },
  {
    "objectID": "posts/2023-03-07-Data-Viz/index.html#analysis-plan",
    "href": "posts/2023-03-07-Data-Viz/index.html#analysis-plan",
    "title": "Data Visualizations in R",
    "section": "Analysis plan",
    "text": "Analysis plan\nSince I have so much data, I’ll want to narrow down my analysis questions for this demo. The main questions I will explore are:\n\n\n   Which artists have the most hit songs?\n\n\n   Are positive songs more energetic and danceable than negative songs?\n\n\n   Do songs in major and minor scale change in popularity over time?\n\n\n   Are songs with explicit lyrics speechier than songs without explicit lyrics?\n\n\n   Does song tempo or duration influence song popularity?\n\nEach of these questions will highlight a different data visualization method. In my experience, it can be helpful to test different plotting methods to find the best way to display results.\n\n  – Which artists have the most hit songs?\nIn order to find out which artists have the most hit songs, I need to count the number of songs by every artist in the data frame. I can easily do this using %&gt;% (pipe) notation, which allows me to express a sequence of multiple operations. The pipe comes from the magrittr package, but tidyverse loads it automatically. Pipes allow me to write a step-by-step command that is executed in a certain order.\nHere, I gather the data contained in df and I ultimately want to store it in a new data frame called artists. To do this, I first group all the data by the unique artist name. I know that this is the first step because it’s the first statement that comes after my initial %&gt;%. Then, while grouping the data by artist, I can count the number of songs by grabbing the length of the song variable.\nFinally, I want to see a list of the top ten artists in descending order by the number of songs.\n\nartists &lt;- df %&gt;%                      # create new data frame\n  group_by(artist) %&gt;%                 # group by unique artist name\n  summarize(SongCount = length(song))  # count the number of songs\n\n# sort list in descending order of number of songs\nartists &lt;- arrange(artists, desc(SongCount))\n\n# print table of top 10 artists\nhead(artists, n = 10)\n\n# A tibble: 10 × 2\n   artist         SongCount\n   &lt;chr&gt;              &lt;int&gt;\n 1 Rihanna               25\n 2 Drake                 23\n 3 Eminem                21\n 4 Calvin Harris         20\n 5 Britney Spears        18\n 6 David Guetta          18\n 7 Chris Brown           17\n 8 Kanye West            17\n 9 Beyoncé               16\n10 Katy Perry            16\n\n\n\nTo visualize this information in a plot, I can save this information as a data frame and make a very simple plot using ggplot2.\n\n# save top ten\nTopTen &lt;- head(artists, n = 10)\n\nggplot(TopTen, aes(x = artist, y = SongCount)) +\n  # outline bars in black, fill with light teal blue\n  geom_col(color = \"black\", fill = \"#fcbc66\", alpha = 0.8) +\n  # order bars in descending order and wrap text so last name appears on second line\n  scale_x_discrete(limits = TopTen$artist, labels = function(x) str_wrap(x, width = 10)) +\n  # label x axis\n  xlab(NULL) + \n  # label y axis\n  ylab(\"Number of Hit Songs\") + \n  # write a descriptive title\n  ggtitle(\"Top Ten Artists with Hit Songs on Spotify from 2000 - 2019\") +\n  # add song count value above each bar\n  geom_text(aes(label = SongCount), position = position_dodge(width = 0.9), vjust = -0.5) \n\n\n\n\n\n\n\n\n\n\n  – Are positive songs more energetic and “danceable” than negative songs?\nIn order to determine if positive songs are both more energetic and more “danceable” than negative songs, I first want to binarize valence into two categories – positive and negative. The Kaggle dataset mentions that songs with a valence greater than 0.5 are considered more positive, while songs with a valence that is less than 0.5 are considered more negative. With this in mind, I will create a new variable called valence.category that reflects this binary split.\nI also want to get some statistical measures for my plot. Using summarySE from the Rmisc package, I can calculate mean, standard deviation, standard error, and 95% confidence intervals for a measurement variable while grouping by another variable. In this case, I want to calculate these statistical measures for both danceability and energy while grouping by the newly created valence.category.\n\n# bin valence values into positive and negative categories\ndf$valence.category[df$valence &gt;= 0.5] &lt;- \"Positive\"\ndf$valence.category[df$valence &lt; 0.5] &lt;- \"Negative\"\n\n# get stats for danceability and energy (mean, 95% confidence interval, etc.)\ndance &lt;- summarySE(df, measurevar = \"danceability\", groupvars = \"valence.category\")\nenergy &lt;- summarySE(df, measurevar = \"energy\", groupvars = \"valence.category\")\n\nNow I can create my plot! I will be making a violin plot to show not only the mean difference between my valence groups, but also what the distribution is within my two valence categories. I will create a plot for energy and for danceability, and combine those into one joint plot using ggarrange.\n\n# build violin plot for danceability\ndance.plot &lt;- ggplot(data = df, aes(x = valence.category, y = danceability,\n                                    fill = valence.category, color = valence.category)) +\n  # violin plot\n  geom_violin(scale = \"area\", alpha = 0.8) +\n  # fill with my selected colors\n  scale_fill_manual(values = c(\"#8dc6bf\",\"#fcbc66\")) +\n  scale_color_manual(values = c(\"#8dc6bf\",\"#fcbc66\")) +\n  # add point for mean of each valence category\n  geom_point(data = dance, aes(x = valence.category, y = danceability), color = \"black\") +\n  # add 95% confidence intervals\n  geom_errorbar(data = dance, aes(ymin = danceability-ci, ymax = danceability+ci),\n                width = 0.25, position = \"dodge\", color = \"black\") +\n  # label x axis\n  xlab(NULL) +\n  # label y axis\n  ylab(\"Danceability\") +\n  # don't include legend\n  theme(legend.position = \"none\")\n\n# build violin plot for energy\nenergy.plot &lt;- ggplot(data = df, aes(x = valence.category, y = energy,\n                                     fill = valence.category, color = valence.category)) +\n  # violin plot\n  geom_violin(scale = \"area\", alpha = 0.8) +\n  # fill with my selected colors\n  scale_fill_manual(values = c(\"#8dc6bf\",\"#fcbc66\")) +\n  scale_color_manual(values = c(\"#8dc6bf\",\"#fcbc66\")) +\n  # add point for mean of each valence category\n  geom_point(data = energy, aes(x = valence.category, y = energy), color = \"black\") +\n  # add 95% confidence intervals\n  geom_errorbar(data = energy, aes(ymin = energy-ci, ymax = energy+ci),\n                width = 0.25, position = \"dodge\", color = \"black\") +\n  # label x axis\n  xlab(NULL) +\n  # label y axis\n  ylab(\"Energy\") +\n  # don't include legend\n  theme(legend.position = \"none\")\n\n# combine dance plot and energy plot using ggarrange\nplot &lt;- ggarrange(dance.plot, energy.plot, ncol = 2)\n# add title and note to plot\nannotate_figure(plot, top = text_grob(\"Danceability and Energy in Positive and Negative Songs\",\n                color = \"black\", face = \"bold\", size = 14),\n                bottom = text_grob(\"Bars indicate 95% confidence intervals around the mean.\",\n                                   color = \"black\", face = \"italic\", size = 8))\n\n\n\n\n\n\n\n\nIt looks like positive songs are both more energetic and more danceable than negative songs, which makes sense. Interestingly, negative songs extend to both the lower and higher ends of the energy and danceability scales, while positive songs tend to be more densely clustered toward the higher end of the scales.\n\n\n  – Do songs in major and minor scales change in popularity over time?\nHere I’m interested to see if songs that are in major versus minor scale change in popularity over time. The major scale is a more commonly used scale, especially in Western music. On the flip, side the minor scale is used when musicians want to evoke a feeling of eeriness or suspense (some examples include “Stairway to Heaven” by Led Zeppelin and “Scarborough Fair” by Simon & Garfunkel).\nI first need to organize the data and calculate an average popularity score for each scale type (the mode variable) and for each year. Then I will create a new character variable called mode.char that indicates whether the scale is major or minor.\n\npopularity &lt;- df %&gt;%\n  group_by(year,mode) %&gt;%\n  summarize(MeanPopularity = mean(popularity))\n\npopularity$mode.char[popularity$mode == 1] &lt;- \"Major\"\npopularity$mode.char[popularity$mode == 0] &lt;- \"Minor\"\n\nNow I can make my plot! Because I’m showing change over time, I decided to use the gganimate package to reveal each data point sequentially on an animated plot.\n\n# make plot\nplot &lt;- ggplot(popularity, aes(x = year, y = MeanPopularity, group = mode.char)) +\n  # animate to reveal points over time\n  transition_reveal(year) +\n  # add point for each year\n  geom_point(aes(color = mode.char), size = 2) +\n  # connect points with line\n  geom_line(aes(color = mode.char), size = 1.1) +\n  # show all years on the x-axis\n  scale_x_continuous(breaks = pretty_breaks(n=20)) +\n  # label x-axis and y-axis\n  ylab(\"Average Popularity\") + xlab(\"Year\") +\n  # add a descriptive title\n  ggtitle(\"Average Popularity of Major and Minor Songs from 2000 - 2019\") +\n  # use my colors and change legend title\n  scale_color_manual(values = c(\"#8dc6bf\",\"#fcbc66\"), name = \"Scale\") +\n  # angle and move x-axis labels and text\n  theme(\n    axis.text.x = element_text(hjust = 1, angle = 45),\n    axis.title.x = element_text(vjust = -1)\n    )\n\n# animate\nanimate(plot, duration = 8, fps = 20, renderer = gifski_renderer(), end_pause = 60)\n\n\n\n\n\n\n\n\n\n\n  – Are songs with explicit lyrics “speechier” than songs without explicit lyrics?\nIn this dataset, “speechiness” is a measure of spoken words in a song. Songs with more exclusively speech-like contents (like a talk show, podcast, etc.) have scores between 0.66 and 1. Songs with a speechiness value between 0.33 and 0.66 describe tracks that contain both music and speech. This range is where I’d expect most of these songs within. Finally, songs with values below 0.33 represent instrumental songs and songs with more music than words.\nFirst, I want to see the range of speechiness values in my dataset to see where songs in this dataset fall.\n\n# find range of speechiness variable\nmin &lt;- min(df$speechiness)\nmax &lt;- max(df$speechiness)\n\n# show histogram of speechiness scores\nhist(df$speechiness, col = \"#FF6347\", xlab = \"Speechiness\", main = \"Histogram of Speechiness Values\")\n\n\n\n# print range\npaste0(\"Speechiness values range from \", min, \" to \", max, \" in this dataset.\", sep = \"\")\n\n[1] \"Speechiness values range from 0.0232 to 0.576 in this dataset.\"\n\n\nInteresting! In this dataset, there are actually more songs that have more instrumental music. I wonder if songs that contain more speech also contain more explicit dialogue than songs with less speech. I can investigate this question using a density plot.\n\ndf$explicit.char[df$explicit == \"False\"] &lt;- \"No\"\ndf$explicit.char[df$explicit == \"True\"] &lt;- \"Yes\"\n\nggplot(df, aes(speechiness)) +\n  # create density plot to show distribution\n  geom_density(aes(fill = factor(explicit.char)), alpha = 0.8) +\n  # use my colors and rename legend\n  scale_fill_manual(values = c(\"#8dc6bf\",\"#fcbc66\"), name = \"Explicit Lyrics\") +\n  # label x-axis and y-axis\n  ylab(\"Density\") + xlab(\"Average Track Speechiness\") +\n  # add a descriptive title\n  ggtitle(\"Average Speechiness of Songs With and Without Explicit Lyrics\")\n\n\n\n\n\n\n\n\nFrom the density plot, we see that yes, songs with more speech and music tend to have more explicit language than songs with less speech!\n\n\n  – Does song tempo or duration influence song popularity?\nFinally, I want to investigate if there is a relationship between song tempo and song popularity or between song duration and song popularity. To do this, I’m going to run two simple linear regressions using base R’s lm function. I want to see if song tempo (independent, predictor variable) influences song popularity (dependent, response variable). I also want to see if song duration in minutes influences song popularity.\n\n# does song tempo influence popularity?\nggplot(df, aes(x = tempo, y = popularity)) +\n  # show data points\n  geom_jitter(size = 1, shape = 1) +\n  # draw regression line\n  geom_smooth(method = \"lm\", color = \"#8dc6bf\", fill = \"#8dc6bf\") +\n  # label x-axis and y-axis\n  xlab(\"Tempo (Beats Per Minute)\") + ylab(\"Average Popularity\")\n\n\n\n\n\n\n\n# run a linear regression\nmodel1 &lt;- lm(popularity ~ tempo, data = df)\nsummary(model1)\n\n\nCall:\nlm(formula = popularity ~ tempo, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-60.668  -3.518   5.860  13.439  29.151 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 58.47742    2.21991  26.342   &lt;2e-16 ***\ntempo        0.01106    0.01804   0.613     0.54    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 21.51 on 1956 degrees of freedom\nMultiple R-squared:  0.0001921, Adjusted R-squared:  -0.000319 \nF-statistic: 0.3759 on 1 and 1956 DF,  p-value: 0.5399\n\n\nBased on the regression results, there does not appear to be an effect of song tempo on popularity (p = .54).\n\n# calculate song duration in minutes\ndf$duration_min &lt;- df$duration_ms/60000\n\n# does song duration influence popularity?\nggplot(df, aes(x = duration_min, y = popularity)) +\n  # show data points\n  geom_jitter(size = 1, shape = 1) +\n  # draw regression line\n  geom_smooth(method = \"lm\", color = \"#fcbc66\", fill = \"#fcbc66\") +\n  # label x-axis and y-axis\n  xlab(\"Song Duration (Minutes)\") + ylab(\"Average Popularity\")\n\n\n\n\n\n\n\n# run a linear regression\nmodel2 &lt;- lm(popularity ~ duration_min, data = df)\nsummary(model2)\n\n\nCall:\nlm(formula = popularity ~ duration_min, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-61.951  -3.755   5.791  13.531  28.854 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   53.3904     2.8842  18.511   &lt;2e-16 ***\nduration_min   1.6860     0.7472   2.256   0.0242 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 21.49 on 1956 degrees of freedom\nMultiple R-squared:  0.002596,  Adjusted R-squared:  0.002086 \nF-statistic: 5.091 on 1 and 1956 DF,  p-value: 0.02416\n\n\nBased on the regression results, there is a significant effect of song duration on popularity (p = .024). As songs get longer, they increase in popularity."
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "# denotes equal contribution\n\n Conversational Linguistic Features Inform Social-Relational Inference \n Helen Schmidt#, Sophia Tran#, John D. Medaglia, Virginia Ulichney, William J. Mitchell, & Chelsea Helion.\nin press  •  Psychonomic Bulletin & Review   pre-print   data + code   abstract \n\n\nAbstract: Whether it is the first day of school or a new job, individuals often find themselves in situations where they must learn the structure of existing social relationships. However, the mechanisms through which individuals evaluate the strength and nature of these existing relationships – social-relational inference – remain unclear. We posit that linguistic features of conversations may help individuals evaluate social relationships and may be associated with social-relational inference. Leveraging a naturalistic behavioral experiment (57 adults; 34,735 observations), participants watched a mid-season episode of a reality television show and evaluated the observed dyadic relationships between contestants. We employed novel person- and stimulus-focused approaches to 1) investigate social-relational inference similarity between participants, 2) examine the association between distinct linguistic features and social-relational inference, and 3) explore the relationship between early season conversation similarity and later perceived relationship formation. We found high pairwise participant response similarity across two relational subtypes (friendship, rivalry), distinct associations between relational judgments and linguistic features, including semantic similarity, sentiment, and clout, and no evidence of an association between early conversation similarity and later friendship inference. These findings suggest that naturalistic conversational content is both a potential mechanism of social-relational inference and a promising avenue for future research.\n\n\n\n\n\n Emotion regulation strategy use and forecasting in response to dynamic, multimodal stimuli \n William J. Mitchell, Joanne Stasiak, Steven A. Martinez, Katelyn G. Cliver, David F. Gregory, Samantha S. Reisman, Helen Schmidt, Vishnu P. Murty, & Chelsea Helion\n2025  •  Journal of Experimental Psychology: General   paper   data + code   abstract \n\n\nAbstract: Successful emotion regulation (ER) requires effective strategy selection. Research suggests that disengagement strategies (e.g., distraction) are more often selected than engagement strategies (e.g., reappraisal) as emotional experiences intensify. However, the extent to which ER strategy choice in controlled circumstances reflects strategy usage during complex, multimodal events is not well understood. The present research uses dynamic, multimodal stimuli (i.e., a haunted house, horror movies) to examine the association between affective intensity and regulatory strategy usage among untrained participants—individuals given no prior regulation instructions or direction. Both a preliminary study (n = 54) and Study 1 (n = 118) failed to find relationships between emotional intensity and strategy usage to downregulate emotions as participants navigated a haunted house. Distraction was self-reported to be less successful than reappraisal at high intensities, contrary to expectations. Participants in Study 2 (n = 152) forecasted regulation strategy usage based upon descriptions of emotionally regulated experiences from the preliminary haunted house study. Affective intensity predicted which strategies forecasters predicted they would use; though, forecasters overpredicted how often distraction was used in practice. Study 3 (n = 242) incorporated strategy usage and forecasting within the same design by showing untrained participants video stimuli of varying intensity and capturing their regulatory responses. Forecasters again predicted using distraction more often than strategy users did in practice. Forecasters also overpredicted how effectively distraction reduced negative affective intensity relative to what strategy users reported. These results may highlight a disconnect between strategy fittedness when self-regulation occurs in uncontrolled, highly intense, or complex circumstances.\n\n\n\n\n\n Integrated Neural Circuitry Supporting Emotion Regulation andDecision Making \n Helen Schmidt & Chelsea Helion\n2025  •  Forthcoming chapter in Neuroeconomics: Core Topics and Current Directions   pre-print   abstract \n\n\nAbstract: Recent research in psychology and neuroscience has begun to closely examine the relationship between emotion regulation and decision making. Emotion regulation strategies allow people to change their thoughts and feelings during emotional situations and events. Successful regulation can be particularly important for a variety of decisions made in day-to-day life. This is especially true for decisions involving risk and reward, where highly rewarding and desirable outcomes are often paired with uncertainty in the likelihood of those outcomes. In this chapter, we aim to operationalize both emotion regulation and decision making in the context of recent findings across psychology and neuroscience. We use an everyday, real-world example involving risk and reward to highlight the relationship between these processes behaviorally and neurocognitively. After presenting a framework, we layer in relevant findings in cognitive neuroscience to explore how the human brain supports these processes, both individually and in an integrated capacity. Finally, we highlight future research implications and open questions in the space.\n\n\n\n\n\n Storytelling changes the content and perceived value of event memories \n Devlin Eckardt, Chelsea Helion, Helen Schmidt, Janice Chen, & Vishnu P. Murty\n2024  •  Cognition   paper   data + code   abstract \n\n\nAbstract: Memories are not only stored for personal recall, but also to communicate knowledge to others in service of adaptive decision-making. Prior research shows that goals to share information can change which content is communicated in memory as well as the linguistic style embedded in this communication. Yet, little is known as to how communication-related alterations in memory narration drive differences of value processing in listeners. Here, we test how memory communication alters multi-featural recall for complex events and the downstream consequence on value estimations in naïve listeners. Participants recalled a memory of playing an exploratory videogame at a 24-h delay under instructions to either share (i.e., social condition) or recall (i.e., control condition) their memory. Sharing goals systematically altered the content and linguistic style of recall, such that narrators from the social condition were biased towards recall of non-episodic details and communicated their memories with more clout, less formality, and less authenticity. Across two independent samples of naïve listeners, these features differentially influenced value estimations of the video game. We found that greater clout was associated with greater enjoyment while listening to memories (hedonic value), and that greater inclusion of non-episodic details resulted in greater willingness to purchase the video game (motivational drive). These findings indicate that sharing an experience as a story can change the content and linguistic tone of memory recall, which in turn shape perceived value in naïve listeners.\n\n\n\n\n\n Perceived Relational Support Is Associated With Everyday Positive, But Not Negative, Affectivity in a U.S. Sample \n Virginia Ulichney, Helen Schmidt, & Chelsea Helion\n2024  •  Personality and Social Psychology Bulletin   paper   data + code   abstract \n\n\nAbstract: Research suggests that perceived social support bolsters emotional well-being. We tested whether perceived support from friends, family, and spouses/partners was associated with reduced negative and greater positive affectivity (i.e., everyday affective baseline), and whether perceived strain in these relationships had opposite effects, accounting for age and relevant covariates. Using data from the third waves of the Midlife in the United States survey and National Study of Daily Experience (n = 1,124), we found negative affectivity was not tied to relational support nor strain, but instead was associated positively with neuroticism and negatively with conscientiousness. In contrast, positive affectivity was related positively to support from friends and family, conscientiousness, and extroversion, and negatively to strain among partners and neuroticism. Exploratory analyses within second-wave Midlife in Japan data (n = 657) suggest patterns for future cross-cultural study. Some relationship dynamics may vary, but perceived support might enhance emotional well-being by bolstering positive, rather than mitigating negative, emotionality."
  },
  {
    "objectID": "publications.html#section",
    "href": "publications.html#section",
    "title": "Publications",
    "section": "",
    "text": "Storytelling changes the content and perceived value of event memories\nEckardt, D., Helion, C., Schmidt, H., Chen, J., & Murty, V.P. (2024). Cognition.\nArticle  Data + Code\n\nIntegrated Neural Circuitry Supporting Emotion Regulation and Decision Making\nSchmidt, H., & Helion, C. (2024). Forthcoming chapter in Neuroeconomics: Core Topics and Current Directions.\nPre-print\n\nPerceived Relational Support Is Associated With Everyday Positive, But Not Negative, Affectivity in a U.S. Sample\nUlichney, V., Schmidt, H., & Helion, C. (2024). Personality and Social Psychology Bulletin.\nArticle  Data + Code"
  },
  {
    "objectID": "publications.html#under-review",
    "href": "publications.html#under-review",
    "title": "Publications",
    "section": "Under Review",
    "text": "Under Review\n# denotes equal contribution\n\n\n\n\n\n\n\nSchmidt, H.#, Tran, S.#, Medaglia, J.D., Ulichney, V., Mitchell, W.J., & Helion, C. (under review). Conversational Linguistic Features Inform Social-Relational Inference.   [pre-print] [data + code]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhen and why does shared reality generalize?\nMahaphanit, W.#, Welker, C.L.#, Schmidt, H., Chang, L.J., & Hawkins, R.X.D. (pre-print).\nPre-print\n\nNeural signatures of recollection are sensitive to memory quality and specific event features\nLadyka-Wojcik, N.#, Schmidt, H.#, Cooper, R.A.#, & Ritchey, M. (under review)\n\nEmotion regulation strategy use and forecasting in response to dynamic, multimodal stimuli\nMitchell, W.J., Stasiak, J., Martinez, S., Cliver, K., Gregory, D., Reisman, S., Schmidt, H., Murty, V.P., & Helion, C. (pre-print).\nPre-print  Data + Code"
  },
  {
    "objectID": "publications.html#in-preparation",
    "href": "publications.html#in-preparation",
    "title": "Publications",
    "section": "In Preparation",
    "text": "In Preparation\n\nNeural Effects of Continuous Ratings During Active Engagement Within a Video fMRI Paradigm\nMitchell, W.J., Schmidt, H., & Helion, C.\n\nLinguistic properties of memory expression influence perceptions of veracity, despite being unrelated to memory accuracy\nMartinez, S., Cliver, K., Mitchell, W.J., Schmidt, H., Ulichney, V., Helion, C., Chein, J., & Murty, V.P."
  },
  {
    "objectID": "portfolio.html",
    "href": "portfolio.html",
    "title": "Portfolio",
    "section": "",
    "text": "Geospatial Analysis & Cartography in R\n\n\n\n\n\n\n\nMaps\n\n\nR\n\n\nOpen Data\n\n\n\n\nA tutorial created for the 2024 Temple University Coding Outreach Group summer workshop series.\n\n\n\n\n\n\nAug 1, 2024\n\n\nHelen Schmidt\n\n\n\n\n\n\n  \n\n\n\n\n30 Day Map Challenge\n\n\n\n\n\n\n\nMaps\n\n\nR\n\n\nOpen Data\n\n\n\n\nThroughout November 2023, I took part in my second #30DayMapChallenge, a challenge to create original maps using geospatial data. Check out the new maps!\n\n\n\n\n\n\nDec 1, 2023\n\n\nHelen Schmidt\n\n\n\n\n\n\n  \n\n\n\n\nGenerating Art in R\n\n\n\n\n\n\n\nData Viz\n\n\nR\n\n\n\n\nThis demo outlines easy ways to generate art in R using random parameter formulas.\n\n\n\n\n\n\nAug 4, 2023\n\n\nHelen Schmidt\n\n\n\n\n\n\n  \n\n\n\n\nIntroduction to Machine Learning in R\n\n\n\n\n\n\n\nR\n\n\nOpen Data\n\n\nMachine Learning\n\n\n\n\nA tutorial created for the 2023 Temple University Coding Outreach Group summer workshop series.\n\n\n\n\n\n\nJun 15, 2023\n\n\nHelen Schmidt\n\n\n\n\n\n\n  \n\n\n\n\n30 Day Chart Challenge\n\n\n\n\n\n\n\nData Viz\n\n\nR\n\n\nOpen Data\n\n\n\n\nIn April 2023, I took part in the #30DayChartChallenge, a month-long challenge to create creative data visualizations around a selection of topics.\n\n\n\n\n\n\nMay 1, 2023\n\n\nHelen Schmidt\n\n\n\n\n\n\n  \n\n\n\n\n30 Day Map Challenge\n\n\n\n\n\n\n\nMaps\n\n\nR\n\n\nOpen Data\n\n\n\n\nThroughout November 2022, I took part in the #30DayMapChallenge, a month-long challenge to create original maps using geospatial data. Check out the results!\n\n\n\n\n\n\nApr 1, 2023\n\n\nHelen Schmidt\n\n\n\n\n\n\n  \n\n\n\n\nData Visualizations in R\n\n\n\n\n\n\n\nData Viz\n\n\nR\n\n\nOpen Data\n\n\n\n\nUsing open-source data and tidyverse packages, this demo explores different data wrangling and plotting techniques in R.\n\n\n\n\n\n\nMar 7, 2023\n\n\nHelen Schmidt\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "publications.html#published",
    "href": "publications.html#published",
    "title": "Publications",
    "section": "Published",
    "text": "Published\n\n\n\n\n\n\n\nEckardt, D., Helion, C., Schmidt, H., Chen, J., & Murty, V.P. (2024). Storytelling changes the content and perceived value of event memories. Cognition, 251, 105884.   [paper]   [data + code] \n\n\n\n\n\n\n\n\n\n\n\nSchmidt, H. & Helion, C. (2024). Integrated Neural Circuitry Supporting Emotion Regulation and Decision Making. Forthcoming chapter in Neuroeconomics: Core Topics and Current Directions.   [pre-print]\n\n\n\n\n\n\n\n\n\n\n\nUlichney, V., Schmidt, H., & Helion, C. (2024). Perceived Relational Support Is Associated With Everyday Positive, But Not Negative, Affectivity in a U.S. Sample. Personality and Social Psychology Bulletin.   [paper]   [data + code]"
  },
  {
    "objectID": "publications.html#under-review-or-in-preparation",
    "href": "publications.html#under-review-or-in-preparation",
    "title": "Publications",
    "section": "Under Review or In Preparation",
    "text": "Under Review or In Preparation\n# denotes equal contribution\n\n\n\n\n\n\n\nSchmidt, H.#, Tran, S.#, Medaglia, J.D., Ulichney, V., Mitchell, W.J., & Helion, C. (under review). Conversational Linguistic Features Inform Social-Relational Inference.   [pre-print]   [data + code]\n\n\n\n\n\n\n\n\n\n\n\nLadyka-Wojcik, N.#, Schmidt, H.#, Cooper, R.A.#, & Ritchey, M. (under review). Neural signatures of recollection are sensitive to memory quality and specific event features.\n\n\n\n\n\n\n\n\n\n\n\nMitchell, W.J., Stasiak, J., Martinez, S., Cliver, K., Gregory, D., Reisman, S., Schmidt, H., Murty, V.P., & Helion, C. (in press). Emotion regulation strategy use and forecasting in response to dynamic, multimodal stimuli. Journal of Experimental Psychology: General.   [pre-print]   [data + code]\n\n\n\n\n\n\n\n\n\n\n\nMahaphanit, W.#, Welker, C.L.#, Schmidt, H., Chang, L.J., & Hawkins, R.X.D. (in prep). When and why does shared reality generalize?   [pre-print]\n\n\n\n\n\nMitchell, W.J., Schmidt, H., & Helion, C. (in prep). Neural Effects of Continuous Ratings During Active Engagement Within a Video fMRI Paradigm.\n\n\nMartinez, S., Cliver, K., Mitchell, W.J., Schmidt, H., Ulichney, V., Helion, C., Chein, J., & Murty, V.P. (in prep). Linguistic properties of memory expression influence perceptions of veracity, despite being unrelated to memory accuracy."
  },
  {
    "objectID": "publications.html#under-review-or-in-preparation-1",
    "href": "publications.html#under-review-or-in-preparation-1",
    "title": "Publications",
    "section": "Under Review or In Preparation",
    "text": "Under Review or In Preparation\n\nNeural Effects of Continuous Ratings During Active Engagement Within a Video fMRI Paradigm\nMitchell, W.J., Schmidt, H., & Helion, C.\n\nLinguistic properties of memory expression influence perceptions of veracity, despite being unrelated to memory accuracy\nMartinez, S., Cliver, K., Mitchell, W.J., Schmidt, H., Ulichney, V., Helion, C., Chein, J., & Murty, V.P."
  },
  {
    "objectID": "publications.html#testing",
    "href": "publications.html#testing",
    "title": "Publications",
    "section": "",
    "text": "Eckardt, D., Helion, C., Schmidt, H., Chen, J., & Murty, V.P. (2024). Storytelling changes the content and perceived value of event memories. Cognition, 251, 105884. \npaper   data + code   abstract \n\n\nAbstract: Memories are not only stored for personal recall, but also to communicate knowledge to others in service of adaptive decision-making. Prior research shows that goals to share information can change which content is communicated in memory as well as the linguistic style embedded in this communication. Yet, little is known as to how communication-related alterations in memory narration drive differences of value processing in listeners. Here, we test how memory communication alters multi-featural recall for complex events and the downstream consequence on value estimations in naïve listeners. Participants recalled a memory of playing an exploratory videogame at a 24-h delay under instructions to either share (i.e., social condition) or recall (i.e., control condition) their memory. Sharing goals systematically altered the content and linguistic style of recall, such that narrators from the social condition were biased towards recall of non-episodic details and communicated their memories with more clout, less formality, and less authenticity. Across two independent samples of naïve listeners, these features differentially influenced value estimations of the video game. We found that greater clout was associated with greater enjoyment while listening to memories (hedonic value), and that greater inclusion of non-episodic details resulted in greater willingness to purchase the video game (motivational drive). These findings indicate that sharing an experience as a story can change the content and linguistic tone of memory recall, which in turn shape perceived value in naïve listeners."
  },
  {
    "objectID": "publications.html#published-or-in-press",
    "href": "publications.html#published-or-in-press",
    "title": "Publications",
    "section": "",
    "text": "Schmidt, H.#, Tran, S.#, Medaglia, J.D., Ulichney, V., Mitchell, W.J., & Helion, C. (in press). Conversational Linguistic Features Inform Social-Relational Inference. Psychonomic Bulletin & Review. \npre-print   data + code   abstract \n\n\nAbstract: Whether it is the first day of school or a new job, individuals often find themselves in situations where they must learn the structure of existing social relationships. However, the mechanisms through which individuals evaluate the strength and nature of these existing relationships – social-relational inference – remain unclear. We posit that linguistic features of conversations may help individuals evaluate social relationships and may be associated with social-relational inference. Leveraging a naturalistic behavioral experiment (57 adults; 34,735 observations), participants watched a mid-season episode of a reality television show and evaluated the observed dyadic relationships between contestants. We employed novel person- and stimulus-focused approaches to 1) investigate social-relational inference similarity between participants, 2) examine the association between distinct linguistic features and social-relational inference, and 3) explore the relationship between early season conversation similarity and later perceived relationship formation. We found high pairwise participant response similarity across two relational subtypes (friendship, rivalry), distinct associations between relational judgments and linguistic features, including semantic similarity, sentiment, and clout, and no evidence of an association between early conversation similarity and later friendship inference. These findings suggest that naturalistic conversational content is both a potential mechanism of social-relational inference and a promising avenue for future research.\n\n\n\n\n\n Schmidt, H. & Helion, C. (2025). Integrated Neural Circuitry Supporting Emotion Regulation and Decision Making.  Forthcoming chapter in Neuroeconomics: Core Topics and Current Directions. \npre-print   abstract \n\n\nAbstract: Recent research in psychology and neuroscience has begun to closely examine the relationship between emotion regulation and decision making. Emotion regulation strategies allow people to change their thoughts and feelings during emotional situations and events. Successful regulation can be particularly important for a variety of decisions made in day-to-day life. This is especially true for decisions involving risk and reward, where highly rewarding and desirable outcomes are often paired with uncertainty in the likelihood of those outcomes. In this chapter, we aim to operationalize both emotion regulation and decision making in the context of recent findings across psychology and neuroscience. We use an everyday, real-world example involving risk and reward to highlight the relationship between these processes behaviorally and neurocognitively. After presenting a framework, we layer in relevant findings in cognitive neuroscience to explore how the human brain supports these processes, both individually and in an integrated capacity. Finally, we highlight future research implications and open questions in the space.\n\n\n\n\n\n Eckardt, D., Helion, C., Schmidt, H., Chen, J., & Murty, V.P. (2024). Storytelling changes the content and perceived value of event memories. Cognition, 251, 105884. \npaper   data + code   abstract \n\n\nAbstract: Memories are not only stored for personal recall, but also to communicate knowledge to others in service of adaptive decision-making. Prior research shows that goals to share information can change which content is communicated in memory as well as the linguistic style embedded in this communication. Yet, little is known as to how communication-related alterations in memory narration drive differences of value processing in listeners. Here, we test how memory communication alters multi-featural recall for complex events and the downstream consequence on value estimations in naïve listeners. Participants recalled a memory of playing an exploratory videogame at a 24-h delay under instructions to either share (i.e., social condition) or recall (i.e., control condition) their memory. Sharing goals systematically altered the content and linguistic style of recall, such that narrators from the social condition were biased towards recall of non-episodic details and communicated their memories with more clout, less formality, and less authenticity. Across two independent samples of naïve listeners, these features differentially influenced value estimations of the video game. We found that greater clout was associated with greater enjoyment while listening to memories (hedonic value), and that greater inclusion of non-episodic details resulted in greater willingness to purchase the video game (motivational drive). These findings indicate that sharing an experience as a story can change the content and linguistic tone of memory recall, which in turn shape perceived value in naïve listeners."
  },
  {
    "objectID": "publications.html#published-in-press",
    "href": "publications.html#published-in-press",
    "title": "Publications",
    "section": "",
    "text": "# denotes equal contribution\n\n Conversational Linguistic Features Inform Social-Relational Inference \n Helen Schmidt#, Sophia Tran#, John D. Medaglia, Virginia Ulichney, William J. Mitchell, & Chelsea Helion.\nin press  •  Psychonomic Bulletin & Review   pre-print   data + code   abstract \n\n\nAbstract: Whether it is the first day of school or a new job, individuals often find themselves in situations where they must learn the structure of existing social relationships. However, the mechanisms through which individuals evaluate the strength and nature of these existing relationships – social-relational inference – remain unclear. We posit that linguistic features of conversations may help individuals evaluate social relationships and may be associated with social-relational inference. Leveraging a naturalistic behavioral experiment (57 adults; 34,735 observations), participants watched a mid-season episode of a reality television show and evaluated the observed dyadic relationships between contestants. We employed novel person- and stimulus-focused approaches to 1) investigate social-relational inference similarity between participants, 2) examine the association between distinct linguistic features and social-relational inference, and 3) explore the relationship between early season conversation similarity and later perceived relationship formation. We found high pairwise participant response similarity across two relational subtypes (friendship, rivalry), distinct associations between relational judgments and linguistic features, including semantic similarity, sentiment, and clout, and no evidence of an association between early conversation similarity and later friendship inference. These findings suggest that naturalistic conversational content is both a potential mechanism of social-relational inference and a promising avenue for future research.\n\n\n\n\n\n Emotion regulation strategy use and forecasting in response to dynamic, multimodal stimuli \n William J. Mitchell, Joanne Stasiak, Steven A. Martinez, Katelyn G. Cliver, David F. Gregory, Samantha S. Reisman, Helen Schmidt, Vishnu P. Murty, & Chelsea Helion\n2025  •  Journal of Experimental Psychology: General   paper   data + code   abstract \n\n\nAbstract: Successful emotion regulation (ER) requires effective strategy selection. Research suggests that disengagement strategies (e.g., distraction) are more often selected than engagement strategies (e.g., reappraisal) as emotional experiences intensify. However, the extent to which ER strategy choice in controlled circumstances reflects strategy usage during complex, multimodal events is not well understood. The present research uses dynamic, multimodal stimuli (i.e., a haunted house, horror movies) to examine the association between affective intensity and regulatory strategy usage among untrained participants—individuals given no prior regulation instructions or direction. Both a preliminary study (n = 54) and Study 1 (n = 118) failed to find relationships between emotional intensity and strategy usage to downregulate emotions as participants navigated a haunted house. Distraction was self-reported to be less successful than reappraisal at high intensities, contrary to expectations. Participants in Study 2 (n = 152) forecasted regulation strategy usage based upon descriptions of emotionally regulated experiences from the preliminary haunted house study. Affective intensity predicted which strategies forecasters predicted they would use; though, forecasters overpredicted how often distraction was used in practice. Study 3 (n = 242) incorporated strategy usage and forecasting within the same design by showing untrained participants video stimuli of varying intensity and capturing their regulatory responses. Forecasters again predicted using distraction more often than strategy users did in practice. Forecasters also overpredicted how effectively distraction reduced negative affective intensity relative to what strategy users reported. These results may highlight a disconnect between strategy fittedness when self-regulation occurs in uncontrolled, highly intense, or complex circumstances.\n\n\n\n\n\n Integrated Neural Circuitry Supporting Emotion Regulation andDecision Making \n Helen Schmidt & Chelsea Helion\n2025  •  Forthcoming chapter in Neuroeconomics: Core Topics and Current Directions   pre-print   abstract \n\n\nAbstract: Recent research in psychology and neuroscience has begun to closely examine the relationship between emotion regulation and decision making. Emotion regulation strategies allow people to change their thoughts and feelings during emotional situations and events. Successful regulation can be particularly important for a variety of decisions made in day-to-day life. This is especially true for decisions involving risk and reward, where highly rewarding and desirable outcomes are often paired with uncertainty in the likelihood of those outcomes. In this chapter, we aim to operationalize both emotion regulation and decision making in the context of recent findings across psychology and neuroscience. We use an everyday, real-world example involving risk and reward to highlight the relationship between these processes behaviorally and neurocognitively. After presenting a framework, we layer in relevant findings in cognitive neuroscience to explore how the human brain supports these processes, both individually and in an integrated capacity. Finally, we highlight future research implications and open questions in the space.\n\n\n\n\n\n Storytelling changes the content and perceived value of event memories \n Devlin Eckardt, Chelsea Helion, Helen Schmidt, Janice Chen, & Vishnu P. Murty\n2024  •  Cognition   paper   data + code   abstract \n\n\nAbstract: Memories are not only stored for personal recall, but also to communicate knowledge to others in service of adaptive decision-making. Prior research shows that goals to share information can change which content is communicated in memory as well as the linguistic style embedded in this communication. Yet, little is known as to how communication-related alterations in memory narration drive differences of value processing in listeners. Here, we test how memory communication alters multi-featural recall for complex events and the downstream consequence on value estimations in naïve listeners. Participants recalled a memory of playing an exploratory videogame at a 24-h delay under instructions to either share (i.e., social condition) or recall (i.e., control condition) their memory. Sharing goals systematically altered the content and linguistic style of recall, such that narrators from the social condition were biased towards recall of non-episodic details and communicated their memories with more clout, less formality, and less authenticity. Across two independent samples of naïve listeners, these features differentially influenced value estimations of the video game. We found that greater clout was associated with greater enjoyment while listening to memories (hedonic value), and that greater inclusion of non-episodic details resulted in greater willingness to purchase the video game (motivational drive). These findings indicate that sharing an experience as a story can change the content and linguistic tone of memory recall, which in turn shape perceived value in naïve listeners.\n\n\n\n\n\n Perceived Relational Support Is Associated With Everyday Positive, But Not Negative, Affectivity in a U.S. Sample \n Virginia Ulichney, Helen Schmidt, & Chelsea Helion\n2024  •  Personality and Social Psychology Bulletin   paper   data + code   abstract \n\n\nAbstract: Research suggests that perceived social support bolsters emotional well-being. We tested whether perceived support from friends, family, and spouses/partners was associated with reduced negative and greater positive affectivity (i.e., everyday affective baseline), and whether perceived strain in these relationships had opposite effects, accounting for age and relevant covariates. Using data from the third waves of the Midlife in the United States survey and National Study of Daily Experience (n = 1,124), we found negative affectivity was not tied to relational support nor strain, but instead was associated positively with neuroticism and negatively with conscientiousness. In contrast, positive affectivity was related positively to support from friends and family, conscientiousness, and extroversion, and negatively to strain among partners and neuroticism. Exploratory analyses within second-wave Midlife in Japan data (n = 657) suggest patterns for future cross-cultural study. Some relationship dynamics may vary, but perceived support might enhance emotional well-being by bolstering positive, rather than mitigating negative, emotionality."
  },
  {
    "objectID": "publications.html#under-review-in-preparation",
    "href": "publications.html#under-review-in-preparation",
    "title": "Publications",
    "section": "Under Review / In Preparation",
    "text": "Under Review / In Preparation\n# denotes equal contribution\n\n Neural signatures of recollection are sensitive to memory quality and specific event features \n Natalia Ladyka-Wojcik#, Helen Schmidt#, Rose A. Cooper#, & Maureen Ritchey\nR&R  •  Journal of Cognitive Neuroscience   abstract \n\n\nAbstract: Episodic memories reflect a bound representation of multimodal features that can be recollected with varying levels of precision. Recent fMRI investigations have demonstrated that the precision and content of information retrieved from memory engage a network of posterior medial temporal and parietal regions co-activated with the hippocampus. Yet, comparatively little is known about how common neural signatures captured by electroencephalography (EEG) may be sensitive to the precise recollection of features bound in episodic memory. Here, we used a multi-feature paradigm previously reported in Cooper & Ritchey (2019) with continuous measures of memory, in conjunction with scalp EEG, to characterize the content and quality of information that drives ERP and oscillatory markers of episodic memory. A common signature of memory retrieval in left posterior regions, called the late positive component, was sensitive to overall memory quality and also to precision of recollection for spatial features. Analysis of oscillatory markers during recollection revealed that alpha/beta desynchronization was modulated by overall memory quality and also by individual features in memory. Importantly, we found evidence of a relationship between these two neural markers of memory retrieval, suggesting that they may represent complementary aspects of the recollection experience. These findings demonstrate how time-sensitive and dynamic processes identified with EEG correspond to overall episodic recollection, and also to the retrieval of precise features in memory.\n\n\n\n\n\n When and why does shared reality generalize? \n Wasita Mahaphanit#, Christopher L. Welker#, Helen Schmidt, Luke J. Chang, & Robert D. Hawkins\nin prep  •  PsyArXiv   pre-print   abstract \n\n\nAbstract: Inspired by inductive reasoning models, we test whether generalized shared reality (i.e., the sense of being on the same page) arises through probabilistic inference about latent commonalities. Using a naturalistic text-based chat paradigm, we manipulated whether conversation partners discussed a belief they shared, a belief on which their opinions differed, or a random prompt. Participants discussing shared opinions reported experiencing greater shared reality compared to those discussing differences or random topics. Moreover, participants who made broader inferences about additional beliefs they might share with their partners also reported greater shared reality. While discussing shared opinions can induce an overall greater sense of shared reality, participants discussing differences leveraged their conversation to establish shared realities about other topics. We demonstrate that shared reality can emerge in multiple ways during initial interactions, establishing a foundation for future mechanistic investigations within an inductive inference framework."
  }
]